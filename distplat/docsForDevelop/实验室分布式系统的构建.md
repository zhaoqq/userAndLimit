## 分布式系统的构建

####日期 2017/05/29

1. #### 操作系统安装  

   > 1. Centos-7-x86_64版本。安装操作系统时，如果是服务器机器，需要配置RAID阵列，根据不同型号的服务器进行不同的操作
   > 2. 确保光驱可用，因为需要使用光盘安装操作系统。
   > 3. 在操作系统安装完成后，建立管理员用户hadoop，记录帐号密码，记录机器的IP地址。

   ​

2. #### 系统基础配置

   > 1. 开启sshd服务(一般情况下默认开启)
   >
   >    ```sh
   >    service sshd start
   >    ```
   >
   > 2. 每台机器都要生成ssh密钥，并配置免密码登录
   >
   >    ```shell	
   >    ssh-keygen -t rsa  #输入命令后一路回车即可
   >    ```
   >
   >    把所有的机器的~/.ssh/id_rsa.pub 内容都加到每台机器的 ~/.ssh/authorized_keys 中；可以使用cat或者scp命令，最后使用如下命令验证
   >
   >    ```shell
   >    ssh localhost #如果不需要密码即可登录，说明配置成功
   >    ```
   >
   > 3.  在/home/hadoop目录下建立一个名字为opt的文件夹，所有的应用程序都放在此目录下
   >
   >    > 配置java环境，其版本是 jdk1.8.0_101
   >
   > 4. 添加环境变量，包括JAVA_HOME等
   >
   >    ```shell
   >    # 执行命令
   >    vim ~/.bashrc #修改环境变量， 在文件中增加如下内容
   >
   >    # 或切换到root用户，修改全局的环境变量
   >    vim /etc/profile
   >
   >    # User specific aliases and functions
   >    export JAVA_HOME=/home/hadoop/opt/jdk1.8.0_101
   >    export CLASSPATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar
   >
   >    export HADOOP_HOME=/home/hadoop/opt/hadoop
   >    export ZOOKEEPER_HOME=/home/hadoop/opt/zookeeper
   >    export HBASE_HOME=/home/hadoop/opt/hbase
   >    export MAVEN_HOME=/home/hadoop/opt/maven
   >    export SCALA_HOME=/home/hadoop/opt/scala
   >    export SPARK_HOME=/home/hadoop/opt/spark
   >    export SBT_HOME=/usr/share/sbt/bin/sbt
   >
   >    export ROCKETMQ_HOME=/home/hadoop/opt/RocketMQ/devenv
   >    export ROCKETMQ_CLASSPATH=$ROCKETMQ_HOME/lib
   >
   >    export PATH=$JAVA_HOME/bin:$HADOOP_HOME/bin:/home/hadoop/opt/sbt/:$PATH
   >
   >
   >    # 执行命令
   >    source ~/.bashrc #使修改内容生效
   >    ```
   >
   > 5. 修改网络配置
   >
   >    ```shell
   >    sudo vim /etc/hosts #添加ip地址与主机名的映射
   >    #在该文件下加入如下内容,ip地址根据机器的真实ip对应填写
   >    Master ip
   >    Slave1 ip
   >    Slave2 ip
   >    ```
   >
   >    ```shell
   >    ssh Master
   >    ssh Slave1 
   >    #测试修改是否生效
   >    ```

   #### 

3. #### 安装分布式计算的相关程序

   1. 把程序文件都放入指定的文件夹

      > 在主文件夹下创建一个opt文件夹，即 **/home/hadoop/opt**, 将所有程序的文件全部放进来
      >
      > 目录结构为：
      >
      >  + /home/hadoop/opt
      >    + hadoop
      >    + zookeeper
      >    + ...
      >    + ...

   2. 在每台机器上进行相同的配置，包括系统基础配置和文件田间

   3. 修改各个程序相关的配置文件

      - **hadoop**

        - 其配置文件的目录 **opt/hadoop/etc/hadoop** 
        - 修改**-env.sh**中的JAVA_HOME
        - 配置**slaves** 

          ```shell
          localhost
          Slave1

          # 此文件中填写各个节点的host，每行一个...
          ```

        - 配置**core-site.xml**

        - ```xml
          <configuration>
          <property>
                          <name>fs.defaultFS</name>
                          <value>hdfs://Master:9000</value>
                  </property>
                  <property>
                          <name>hadoop.tmp.dir</name>
                          <value>/home/hadoop/opt/hadoop/tmp</value>
                          <description>Abase for other temporary directories.</description>
                  </property>
          </configuration>
          ```

        - 配置**hdfs-site.xml**

        - ```xml
          <configuration>
          	<property>
                          <name>dfs.namenode.secondary.http-address</name>
                          <value>Master:50090</value>
              </property>
              <property>
                          <name>dfs.replication</name>
                          <value>2</value>
              </property>
              <property>
                          <name>dfs.namenode.name.dir</name>
                          <value>/home/hadoop/opt/hadoop/tmp/dfs/name</value>
              </property>
              <property>
                          <name>dfs.datanode.data.dir</name>
                          <value>/home/hadoop/opt/hadoop/tmp/dfs/data</value>
              </property>
          </configuration>

          ```

        - 修改**mapred-site.xml**

        - ```xml
          <configuration>
                   <property>
                          <name>mapreduce.framework.name</name>
                          <value>yarn</value>
                  </property>
                  <property>
                          <name>mapreduce.jobhistory.address</name>
                          <value>Master:10020</value>
                  </property>
                  <property>
                          <name>mapreduce.jobhistory.webapp.address</name>
                          <value>Master:19888</value>
                  </property>
          </configuration>
          ```

        - 修改**yarn-site.xml**，由于新版本是使用yarn管理的，所以此文件和上一个mapred-site.xml中的配置项可能需要调整，暂时还不清楚，先这样写。

        - ```xml
          <configuration>
                    <property>
                          <name>yarn.resourcemanager.hostname</name>
                          <value>Master</value>
                  </property>
                  <property>
                          <name>yarn.nodemanager.aux-services</name>
                          <value>mapreduce_shuffle</value>
                  </property>
          </configuration>
          ```

        - 将配置文件分发给所有节点， scp  -r ~/opt/hadoop hadoop@Slave1:~/opt/hadoop 这一步骤也可以手动进行。总之，每个节点都作如上配置

        - 运行hadoop，进行测试。

        - ```bash
          $ hadoop namenode -format
          start-dfs.sh
          start-yarn.sh
          jps
          ```

        - ```bash
          $ jps  #run on master
          3407 SecondaryNameNode
          3218 NameNode
          3552 ResourceManager
          3910 Jps
          ```

        - ```bash
          $ jps   #run on slaves
          2072 NodeManager
          2213 Jps
          1962 DataNode
          ```

        - **maven**

          - 不需要修改任何东西，确保bashrc中的maven_home存在即可

        - **spark**

          - 在各个节点的*~opt/spark/conf目录下配置**slaves**

          - ```shell
            localhost
            Slave1

            # 此文件中填写各个节点的host，每行一个...
            ```

          - 运行 *~opt/spark/sbin/start-all.sh* 

          - Master和Slave1上应该有如下进程

          - ```bash
            $ jps # run on Master
            7949 Jps
            7328 SecondaryNameNode
            7805 Master
            7137 NameNode
            7475 ResourceManager

            $jps  # run on Slave1
            3132 DataNode
            3759 Worker
            3858 Jps
            3231 NodeManager

            $ ~/opt/spark/bin/run-example SparkPi 10 # have a test
            ```

        - **scala** 无需配置

        - **hbase** 

          - 将程序文件放到opt文件夹下，进入到conf目录中

          - 修改**hbase-site.xml**

          - ```xml
            <configuration> 
            	<property>
            		<name>hbase.rootdir</name>
            		<value>hdfs://Master:9000/hbase</value> 
            	</property>
            	
            	<property>
            		<name>hbase.cluster.distributed</name>
            		<value>true</value>
            	</property>
            	
            	<property>
            		<name>hbase.zookeeper.quorum</name>
            		<value>Master,Slave1,Slave2</value>
            	</property>
            	
            	<property>
            	  <name>zookeeper.session.timeout</name>
            	  <value>60000</value>
            	</property>
            	
            	<property>
            	  <name>hbase.zookeeper.property.clientPort</name>
            	  <value>2181</value>
            	</property>
            	
            	<property>
            	  <name>hbase.master</name>
            	  <value>Master</value>
            	</property>
            	
            	<property>
            	  <name>hbase.master.info.port</name>
            	  <value>60010</value>
            	</property>
            	
            	<property>
            	  <name>hbase.master.port</name>
            	  <value>60000</value>
            	</property>

            </configuration>
            ```

          - 修改**regionservers**, (类似于hadoop以及spark的slaves文件)

          - ```bash
            Master
            Slave1
            ```

          - 修改 **hbase-env.sh**

            ```bash
            export HBASE_MANAGES_ZK=false
            ```

          - 运行并测试

        - **zookeeper** 

          - 修改conf/zoo.cfg

          - ```shell
            tickTime=2000
            dataDir=/home/hadoop/opt/zookeeper/data
            clientPort=2181
            initLimit=5
            syncLimit=2
            server.1=Master:2888:3888
            server.2=Slave1:2888:3888
            ```

          - 在每个节点的dataDir目录内创建myid文件，文件内容为server的编号，即1,2,3。。 每个文件中仅有一个数字，注意文件夹和文件的权限

          - 运行
        - **hbase**
          - 在hbase的目录下创建目录，**pids** 并修改conf/hbase-env.sh, 设置
            **export HBASE_PID_DIR=/home/hadoop/opt/hbase/pids**


   ​

4. #### 官方文档 

   > [hadoop](http://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-common/ClusterSetup.html "hadoop installation.")
   >
   > [yarn](http://www.alexjf.net/blog/distributed-systems/hadoop-yarn-installation-definitive-guide/ "configure yarn." )
   >
   > [hbase](http://hbase.apache.org/book.html#configuration "install singlenode, then modify the configure file.")
   >
   > [apache-maven](https://maven.apache.org/install.html "easy to install.")
   >
   > [spark](https://spark.apache.org/docs/2.1.0/ "spark docs.")
   >
   > [scala](http://www.scala-lang.org "download biniary then run it.")
   >
   > [zookeeper](https://zookeeper.apache.org/doc/r3.4.9/zookeeperStarted.html "first singlealone, then configure cluster.")
   >
   > [zookeeper-appendix](https://www.cloudera.com/documentation/enterprise/5-9-x/topics/cdh_ig_zookeeper_package_install.html)
   >
   > [RocketMQ](https://github.com/alibaba/RocketMQ/wiki/Quick-Start "download then run scripts, read the cluster configuration files.")

5. #### 其他问题

   - 出现如下的Warning信息

     ```bash
     17/06/15 21:42:48 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
     ```

     服务器是64bit的，某个库文件是在32bit系统下编译的，对hadoop的使用没有影响，具体请见

     [](https://stackoverflow.com/questions/19943766/hadoop-unable-to-load-native-hadoop-library-for-your-platform-warning)

   - 在设置了authorized_keys后，仍然无法对新添加的服务器免密码登录，在新添加的服务器上执行如下命令

     ```bash
     sudo chmod 600 ~/.ssh/authorized_keys
     ```

   - 各个程序的版本号说明

     ```bash
     #所需程序的版本号
     # javajdk jdk1.8.0_101
     # hadoop 2.7.3
     # hbase 1.2.4
     # apache-maven 2.3.9
     # spark 2.1.0 based on hadoop 2.7
     # scala 2.12.1
     # zookeeper 3.4.9
     # RocketMQ 3.5.8
     # 在安装目录中的名字需改为 hadoop/hbase/maven/spark/zookeeper/RocketMQ
     ```
   - 在运行程序时要确保tomcat是64bit java是64bit。也可以都是32，总之要一致

     ​

